{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Lecture des documents XML/TEI**\n",
    "\n",
    "https://komax.github.io/blog/text/python/xml/parsing_tei_xml_python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from slugify import slugify\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_tei_to_df(folder:str) -> pd.DataFrame:\n",
    "    # créer une liste de dictionnaires qui deviendra notre dataframe\n",
    "    df = []\n",
    "\n",
    "    # Renommer les fichiers au besoin\n",
    "    tei_docs = os.listdir(folder)\n",
    "\n",
    "    for file in tei_docs:\n",
    "        tei_doc = '-'.join(slugify(file).split('-')[:6])\n",
    "        os.rename(os.path.join(folder, file), os.path.join(folder, tei_doc + '.xml'))\n",
    "\n",
    "        # Parser le XML du fichier avec BeautifulSoup\n",
    "        with open(f'{folder}/{tei_doc}.xml', 'r', encoding='utf-8') as tei:\n",
    "            soup = BeautifulSoup(tei, features='xml')\n",
    "\n",
    "            # doi\n",
    "            try:\n",
    "                doi = soup.find('idno', type='DOI').getText()\n",
    "            \n",
    "            except:\n",
    "                print(tei_doc, 'no doi info')\n",
    "                doi=None\n",
    "\n",
    "            # premier auteur\n",
    "            try:\n",
    "                first_author = soup.author.persName.get_text(\" \")\n",
    "            except:\n",
    "                print(tei_doc, 'no first author info')\n",
    "                first_author=None\n",
    "\n",
    "            # titre\n",
    "            try:\n",
    "                title = soup.title.getText()\n",
    "            except:\n",
    "                print(tei_doc, 'no title info')\n",
    "                title=None\n",
    "\n",
    "            # résumé\n",
    "            abstract = soup.abstract.get_text() if soup.abstract else None       \n",
    "\n",
    "            # date de publication\n",
    "            try:\n",
    "                publication_date = soup.find('date', type='published')['when']\n",
    "            except:\n",
    "                print(tei_doc, 'no date info')\n",
    "                publication_date=None\n",
    "\n",
    "            # nom du périodique\n",
    "            try:\n",
    "                journal_title = soup.find('title', level='j').getText()\n",
    "            except:\n",
    "                print(tei_doc, 'no journal info')\n",
    "                journal_title=None\n",
    "\n",
    "            # nom de l'éditeur\n",
    "            try:\n",
    "                publisher = soup.publisher.getText()            \n",
    "            except:\n",
    "                print(tei_doc, 'no publisher info')\n",
    "                publisher=None\n",
    "\n",
    "            # corps du texte\n",
    "            body = ''\n",
    "            try:\n",
    "                body = \"\\n\".join(\n",
    "                    [\n",
    "                        (section.find('head').get_text() if section.find('head') else \"\") +\n",
    "                        \"\\n\" +\n",
    "                        \"\\n\".join([p.get_text() for p in section.find_all('p')])\n",
    "                        for section in soup.body.find_all('div', recursive=False)\n",
    "                    ]\n",
    "                )\n",
    "                    \n",
    "            except:\n",
    "                print(tei_doc, 'no body info')\n",
    "                body=None\n",
    "\n",
    "\n",
    "            # Stocker le corps du texte dans un fichier txt (pour consultation)\n",
    "            txt_file_name = f'../txts/{folder[11:]}/{tei_doc}.txt'\n",
    "            with open(txt_file_name, 'w', encoding='utf-8') as f:\n",
    "                f.write(body)                 \n",
    "\n",
    "            dic = {\n",
    "                'doi' : doi,\n",
    "                'first_author' : first_author,\n",
    "                'title' : title,\n",
    "                'abstract' : abstract,\n",
    "                'published' : publication_date,\n",
    "                'journal' : journal_title,\n",
    "                'publisher' : publisher,\n",
    "                'body' : body\n",
    "            }\n",
    "\n",
    "        df.append(dic)\n",
    "\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azzopardi-et-al-2011-report-on no doi info\n",
      "azzopardi-et-al-2013-how-query no doi info\n",
      "berryman-2006-what-defines-enough-information no doi info\n",
      "bouzdine-chameeva-et-al-2006-stopping no doi info\n",
      "browne-et-al-2005-stopping-rule no doi info\n",
      "browne-et-al-2007-cognitive-stopping no doi info\n",
      "card-et-al-2001-information-scent no doi info\n",
      "dalton-and-charnigo-2004-historians-and no doi info\n",
      "dostert-and-kelly-2009-users-stopping no doi info\n",
      "duff-and-johnson-2002-accidentally-found no doi info\n",
      "gerhart-and-windsor-2017-cognitive-stopping no doi info\n",
      "keen-1992-presenting-results-of-experimental no doi info\n",
      "kraft-and-lee-1979-stopping-rules no doi info\n",
      "nickles-et-al-1995-judgment-based no doi info\n",
      "simon-1955-a-behavioral-model-of no doi info\n",
      "simon-1955-a-behavioral-model-of no date info\n",
      "simon-1955-a-behavioral-model-of no journal info\n",
      "white-and-harding-2008-identifying-auditor no doi info\n",
      "finnell-and-fontane-2010-reference-question no doi info\n",
      "kao-et-al-2003-decision-support no doi info\n",
      "prehanto-et-al-2020-library-book no doi info\n",
      "puarungroj-et-al-2018-investigating-factors no doi info\n",
      "renaud-et-al-2015-mining-library no doi info\n",
      "yaco-et-al-2016-linking-special no doi info\n",
      "amin-et-al-2008-understanding-cultural no doi info\n",
      "bates-2001-information-needs-and-seeking no doi info\n",
      "beaudoin-and-brady-2011-finding-visual no doi info\n",
      "cobbledick-1996-the-information-seeking-behavior no doi info\n",
      "cowan-2004-informing-visual-poetry-information no doi info\n",
      "cowan-2004-informing-visual-poetry-information no first author info\n",
      "frank-1999-student-artists-in-the no doi info\n",
      "gregory-2007-under-served-or-under no doi info\n",
      "larkin-2010-looking-to-the-future no doi info\n",
      "larkin-2013-a-study-of-information no doi info\n",
      "lee-and-haddow-2017-artists-information no doi info\n",
      "robinson-2014-from-hieroglyphs-to-hashtags no doi info\n",
      "ucak-2011-information-use-in-art no doi info\n",
      "van-zijl-and-gericke-2014-information no doi info\n",
      "zreik-et-al-2021-the-information no doi info\n",
      "ahmad-2021-towards-intelligent-systems-modelling no doi info\n",
      "fu-and-carmen-2015-migration-to no doi info\n",
      "grammenis-and-mourikis-2018-migrating-from no doi info\n",
      "kamarudin-et-al-2018-a-study no doi info\n",
      "kamarudin-et-al-2018-a-study no journal info\n",
      "amudha-et-al-2019-human-library no doi info\n",
      "brown-2016-school-libraries-as-power no doi info\n",
      "goebel-2011-fags-blacks-and-hutterites no doi info\n",
      "goebel-2011-fags-blacks-and-hutterites no journal info\n",
      "kudo-et-al-2011-bridging-differences no doi info\n",
      "liu-2014-human-library-and-its no doi info\n",
      "naik-2021-role-of-human-library no doi info\n",
      "naik-2021-role-of-human-library no journal info\n",
      "auster-and-chan-2004-reference-librarians no doi info\n",
      "chidiadi-2019-effect-of-library-staff no doi info\n",
      "dalton-et-al-2000-barriers-to no doi info\n",
      "lamptey-et-al-2013-motivation-and no doi info\n",
      "pan-et-hovde-2010-professional-development no doi info\n",
      "walter-2006-instructional-improvement-building-capacity no doi info\n"
     ]
    }
   ],
   "source": [
    "xml_dirs = os.listdir('../xml_tei')\n",
    "\n",
    "for xml_dir in xml_dirs:\n",
    "    df = xml_tei_to_df('../xml_tei/' + xml_dir)\n",
    "\n",
    "    csv_file_name = xml_dir\n",
    "    df.to_csv('../csvs/' + xml_dir + '.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
